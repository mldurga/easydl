<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Fastai fit_one_cycle &amp; fine_tune and Super-Convergence (Leslie Smith) | mldurga</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Fastai fit_one_cycle &amp; fine_tune and Super-Convergence (Leslie Smith)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploring Source code of fastai" />
<meta property="og:description" content="Exploring Source code of fastai" />
<link rel="canonical" href="https://mldurga.github.io/easydl/paper_reading/2021/10/14/super_convergence.html" />
<meta property="og:url" content="https://mldurga.github.io/easydl/paper_reading/2021/10/14/super_convergence.html" />
<meta property="og:site_name" content="mldurga" />
<meta property="og:image" content="https://mldurga.github.io/easydl/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-14T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-10-14T00:00:00-05:00","url":"https://mldurga.github.io/easydl/paper_reading/2021/10/14/super_convergence.html","@type":"BlogPosting","image":"https://mldurga.github.io/easydl/images/some_folder/your_image.png","headline":"Fastai fit_one_cycle &amp; fine_tune and Super-Convergence (Leslie Smith)","dateModified":"2021-10-14T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mldurga.github.io/easydl/paper_reading/2021/10/14/super_convergence.html"},"description":"Exploring Source code of fastai","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/easydl/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://mldurga.github.io/easydl/feed.xml" title="mldurga" /><link rel="shortcut icon" type="image/x-icon" href="/easydl/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/easydl/">mldurga</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/easydl/about/">About Me</a><a class="page-link" href="/easydl/search/">Search</a><a class="page-link" href="/easydl/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Fastai ```fit_one_cycle``` &amp; ```fine_tune``` and Super-Convergence (Leslie Smith)</h1><p class="page-description">Exploring Source code of fastai</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-10-14T00:00:00-05:00" itemprop="datePublished">
        Oct 14, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/easydl/categories/#paper_reading">paper_reading</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/mldurga/easydl/tree/master/_notebooks/2021-10-14-super_convergence.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/easydl/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/mldurga/easydl/master?filepath=_notebooks%2F2021-10-14-super_convergence.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/easydl/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/mldurga/easydl/blob/master/_notebooks/2021-10-14-super_convergence.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/easydl/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Topology-of-Loss-function">Topology of Loss function </a></li>
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#Learning-rate-(LR)-and-Weight-updataion">Learning rate (LR) and Weight updataion </a></li>
<li class="toc-entry toc-h2"><a href="#Cyclical-Learning-Rate-(CLR)">Cyclical Learning Rate (CLR) </a></li>
<li class="toc-entry toc-h2"><a href="#Super-Convergence">Super-Convergence </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Momentum">Momentum </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#fit_one_cycle-and-fine_tune-of-fastai">fit_one_cycle and fine_tune of fastai </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Exploring-source-code-in-fastai-library-can-give-good-insights">Exploring source code in fastai library can give good insights </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Credits">Credits </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-10-14-super_convergence.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/mldurga/easydl/blob/master/_notebooks/2021-10-14-super_convergence.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Topology-of-Loss-function">
<a class="anchor" href="#Topology-of-Loss-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Topology of Loss function<a class="anchor-link" href="#Topology-of-Loss-function"> </a>
</h2>
<p>Nothing is more explainable than this 

</p>
<center>
    <div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="und" dir="ltr"><a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DGLSL?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきGLSL</a><br>float i,e,f,s,g,k=.01;for(o++;i++&lt;1e2;g+=min(f,max(.03,e))*.3){s=2.;vec3 p=vec3((FC.xy-r/s)/r.y*g,g-s);p.yz*=rotate2D(-.8);p.z+=t;for(e=f=p.y;s&lt;2e2;s/=.6)p.xz*=rotate2D(s),e+=abs(dot(sin(p*s)/s,p-p+.4)),f+=abs(dot(sin(p.xz*s*.6)/s,r/r));o+=(f&gt;k*k?e:-exp(-f*f))*o*k;} <a href="https://t.co/aUHgeJEroY">pic.twitter.com/aUHgeJEroY</a></p>— yonatan (@zozuar) <a href="https://twitter.com/zozuar/status/1443012484189888515?ref_src=twsrc%5Etfw">September 29, 2021</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</center>


</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
<p>Until publication of the papers <a href="https://arxiv.org/pdf/1506.01186.pdf">1</a>,<a href="https://arxiv.org/pdf/1803.09820.pdf">2</a>,<a href="https://arxiv.org/pdf/1708.07120.pdf">3</a> by Mr Leslie Smith, finding learning rate of neural networks training is largely a black art and often requires extensive practice and expertise to set good hyperparameters. Mr Smith's contribution greatly helped reserach community on overall understanding of the topology of loss function. Unlike typical Machine Learning papers, Smith's Papers are very much approachable and invaluable. I have tried to reproduce fastai source code of implementation of 1cycle policy inspired from Smith's papers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learning-rate-(LR)-and-Weight-updataion">
<a class="anchor" href="#Learning-rate-(LR)-and-Weight-updataion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Learning rate (LR) and Weight updataion<a class="anchor-link" href="#Learning-rate-(LR)-and-Weight-updataion"> </a>
</h2>
<p>In neural networks training, loss function (simply distance between target value and predicted value) must be decreased with each iteration. SGD - stochastic gradient descent is the method to achieve the above stated goal. If you can observe the above twitter card, loss function topology will be more or less have same features. Identifying global minimum of that topology is the sole aim of any Machine learning practitioner. However, training gets trapped over local minima and model underperforms. This is where Smiths ideas catapulted training neural networks to the next level.</p>
<p><img src="https://user-images.githubusercontent.com/19243618/137344851-460b2d6d-30a4-4f31-b4fc-6382581dd87d.png" alt="image"></p>
<p><code>w.new=w.old - gradient(w.old) * lr</code></p>
<p>above image gives general idea of Lerning Rate value impact on convergence of loss function. weights will get updated for each iteration at the rate of choosen LR. Low LR can have effect of trapping at <a href="https://en.wikipedia.org/wiki/Saddle_point">saddle</a> points and local minima, High LR can immediately be diverged and loss value increases greatly. Until Smith's papers, setting right LR has been a great challenge.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cyclical-Learning-Rate-(CLR)">
<a class="anchor" href="#Cyclical-Learning-Rate-(CLR)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cyclical Learning Rate (CLR)<a class="anchor-link" href="#Cyclical-Learning-Rate-(CLR)"> </a>
</h2>
<p>Conventionally LR is a fixed value and tends to be decreased over a period of training until a good accuracy is obtained. Smith introduced novel technique of varying learning rate in cyclical fashion resulted in huge gains in accuracy in few iterations compared to the conventional practices.</p>
<p><img src="https://user-images.githubusercontent.com/19243618/137067445-bef503ca-dc77-447b-88e7-ba6126908b2d.jpg" alt="cifar_LR"></p>
<p>the CLR approach has clearly outperformed other techniques of setting LR as hown in figure. CLR achieved same accuracy within 20k iterations compared to 80k iterations of other techniques.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://user-images.githubusercontent.com/19243618/137253367-2cf2c603-85ef-4c10-abfc-24555536025e.png" alt="image"></p>
<p>LR has to be varied between two bounds called maximum bound and minimum bound. These can be found from LR range test, which is identifying minimum and maximum learning rate values where accuracy is actually increasing, by doing few iteratrions of training. Due to simplicity, triangular learning rate policy was adopted for most of the cases. following terminology helps in understanding setting of learning rate.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>epoch: one pass through of the entire dataset</li>
<li>batch size: No of images in a mini batch</li>
<li>iteration: training over a mini batch</li>
</ul>
<p>Lets take 50,000 images to be trained and with a 100 images per minibatch</p>
<ul>
<li>No of iterations per epoch =&gt; (50000/100) =500</li>
<li>stepsize : Generally 2 times epoch, so every 1000 iterations we have one increaing learning rate and next 1000 iterations we have one decreasing learning rate, this becomes one cycle</li>
</ul>
<p>Smiths experiments shows that generally 3 cycles have trained the network within short iterations compared to conventional LR methods. However 1cycle <a href="https://arxiv.org/pdf/1708.07120.pdf">paper</a> in 2018 stated that one cycle is sufficient to train the network when very large learning rates are used.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Super-Convergence">
<a class="anchor" href="#Super-Convergence" aria-hidden="true"><span class="octicon octicon-link"></span></a>Super-Convergence<a class="anchor-link" href="#Super-Convergence"> </a>
</h2>
<p>Cyclic learning rates coupled with large values of learning rates leads to convergence much faster than standard training methods. The large learning rates allows training to jump over the local minimas and will find a way to global minima in much less time. Cyclical nature of the learning rates enables training to first slowly converge then moves at faster speeds to traverse the valley and again slows the pace to finally converge to final accuracy level.</p>
<p><img src="https://user-images.githubusercontent.com/19243618/137189466-0b3eca30-9ad9-4e5b-9cf6-6b1c4deb5be9.png" alt="image"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Above images are from super-convergence paper. Figure (a) clearly shows the dominance of Super-Convergence approach denoted by CLR. With CLR range 0.1-3 (Learning rate bounds) accuracy obtained 92.4% within 10k iterations compared to 80k iterations of normal training methods on CIFAR-10 Dataset, ResNet-56 architecture.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To reiterate author words "Always use one cycle that is smaller than the total number of iterations/epochs and allow the learning rate to decrease several orders of magnitude less than the initial learning rate for the remaining iterations". This is called 1cycle policy or Super-Convergence. Since 1cycle policy have regularisation effect on overall training process, care must be taken to balance the remianing regularisation techniques like weight-decay, batch size, drop out etc.. depending on the dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The maximum learnng rate will be obtained from the LR range test, in which maximum learning rate at which accuracy stops increasing will be taken as max LR and minimum LR will be factor of 10 to 20 less than the max LR.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Momentum">
<a class="anchor" href="#Momentum" aria-hidden="true"><span class="octicon octicon-link"></span></a>Momentum<a class="anchor-link" href="#Momentum"> </a>
</h3>
<p>According to Leslie papers, Momentum is as important as learning rate for training the network. The value of momentum observed to be decreasing while learning rate value is increasing in a stepsize of 1cycle policy. Momentum is an attempt to maintain consistent direction of SGD (stochastic Gradient Direction). If we set momentum at 90%, it means we will take 90% of the previous direction and 10% of the new direction. Intuitiviely we can look at moomentum as a process of giving more weight to new gradients or directions to find flatter area. Leslie smith suggest to use momentum values between 0.85 and 0.95 for training purpose.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="fit_one_cycle-and-fine_tune-of-fastai">
<a class="anchor" href="#fit_one_cycle-and-fine_tune-of-fastai" aria-hidden="true"><span class="octicon octicon-link"></span></a><code>fit_one_cycle</code> and <code>fine_tune</code> of fastai<a class="anchor-link" href="#fit_one_cycle-and-fine_tune-of-fastai"> </a>
</h2>
<p>The above paper has been implemented in fastai with certain modifications. Source code of fastai related to these functions were presented here. Since this library is designed with lot of functionality, and all of them cant be reproduced here, interested can explore the same in <a href="https://github.com/fastai/fastai/tree/master/fastai">github</a> for entire source code.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets explore bit by bit. First we will look at <code>fine_tune()</code> then drill down gradully</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fine_tune</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span><span class="n">Learner</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">,</span> <span class="n">freeze_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_mult</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
              <span class="n">pct_start</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">div</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="s2">"Fine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR."</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">freeze_epochs</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">base_lr</span><span class="p">),</span> <span class="n">pct_start</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">base_lr</span> <span class="o">/=</span> <span class="mi">2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">base_lr</span><span class="o">/</span><span class="n">lr_mult</span><span class="p">,</span> <span class="n">base_lr</span><span class="p">),</span> <span class="n">pct_start</span><span class="o">=</span><span class="n">pct_start</span><span class="p">,</span> <span class="n">div</span><span class="o">=</span><span class="n">div</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>fine_tune</code> initially freezes pretrained model weights and trains using <code>fit_one_cycle</code> with one epoch to enable random weights in head to adjust to new dataset. After unfreeze entire network will be trained with same <code>fit_one_cycle</code> method with choosen no of epochs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Exploring-source-code-in-fastai-library-can-give-good-insights">
<a class="anchor" href="#Exploring-source-code-in-fastai-library-can-give-good-insights" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploring source code in fastai library can give good insights<a class="anchor-link" href="#Exploring-source-code-in-fastai-library-can-give-good-insights"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://user-images.githubusercontent.com/19243618/137338003-dfdbf632-4ea7-444b-af40-e68319d076d8.png" alt="image"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>pct_start</code> is percentage of overall iterations where LR is increaing. if <code>pct_start</code> is 0.25 that means LR is increasing up to 25 % of iterations and remaining 75 % iterations LR is decreasing. other plot is of momentum, its values varies inverse to the LR and range is between 0.95 to 0.85. However the choice of the momentum values will be depend on the dataset and architectures.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Other Helper functions in source code</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://user-images.githubusercontent.com/19243618/137340342-934f87a6-e379-438f-a661-5fe39b6af111.png" alt="image"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Credits">
<a class="anchor" href="#Credits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Credits<a class="anchor-link" href="#Credits"> </a>
</h2>
<ul>
<li>Leslie Smith Papers <a href="https://arxiv.org/pdf/1506.01186.pdf">1</a>,<a href="https://arxiv.org/pdf/1803.09820.pdf">2</a>,<a href="https://arxiv.org/pdf/1708.07120.pdf">3</a>
</li>
<li>Fastai library <a href="https://github.com/fastai/fastai/tree/master/fastai">github</a>
</li>
<li>Slvain Gugger <a href="https://sgugger.github.io/the-1cycle-policy.html">post</a>
</li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="mldurga/easydl"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/easydl/paper_reading/2021/10/14/super_convergence.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/easydl/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/easydl/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/easydl/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/mldurga" title="mldurga"><svg class="svg-icon grey"><use xlink:href="/easydl/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/durgaamma2005" title="durgaamma2005"><svg class="svg-icon grey"><use xlink:href="/easydl/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
